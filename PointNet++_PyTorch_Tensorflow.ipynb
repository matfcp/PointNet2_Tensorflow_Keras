{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XERrholY9pLq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#PyTorch"
      ],
      "metadata": {
        "id": "XERrholY9pLq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##utils"
      ],
      "metadata": {
        "id": "uZRRqD4q2kEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "EPZu3dtDdfHi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def square_distance(src, dst):\n",
        "    \"\"\"\n",
        "    Calculate Euclid distance between each two points.\n",
        "\n",
        "    src^T * dst = xn * xm + yn * ym + zn * zmï¼›\n",
        "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
        "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
        "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
        "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
        "\n",
        "    Input:\n",
        "        src: source points, [B, N, C]\n",
        "        dst: target points, [B, M, C]\n",
        "    Output:\n",
        "        dist: per-point square distance, [B, N, M]\n",
        "    \"\"\"\n",
        "    B, N, _ = src.shape\n",
        "    _, M, _ = dst.shape\n",
        "    dist = -2 * torch.matmul(src, dst.permute(0, 2, 1))\n",
        "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
        "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
        "    return dist\n",
        "\n",
        "\n",
        "def index_points(points, idx):\n",
        "    \"\"\"\n",
        "\n",
        "    Input:\n",
        "        points: input points data, [B, N, C]\n",
        "        idx: sample index data, [B, S]\n",
        "    Return:\n",
        "        new_points:, indexed points data, [B, S, C]\n",
        "    \"\"\"\n",
        "    device = points.device\n",
        "    B = points.shape[0]\n",
        "    view_shape = list(idx.shape)\n",
        "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
        "    repeat_shape = list(idx.shape)\n",
        "    repeat_shape[0] = 1\n",
        "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
        "    new_points = points[batch_indices, idx, :]\n",
        "    return new_points\n",
        "\n",
        "\n",
        "def farthest_point_sample(xyz, npoint):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        xyz: pointcloud data, [B, N, 3]\n",
        "        npoint: number of samples\n",
        "    Return:\n",
        "        centroids: sampled pointcloud index, [B, npoint]\n",
        "    \"\"\"\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.shape\n",
        "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)\n",
        "    distance = torch.ones(B, N).to(device) * 1e10\n",
        "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)\n",
        "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
        "    for i in range(npoint):\n",
        "        centroids[:, i] = farthest\n",
        "        centroid = xyz[batch_indices, farthest, :].unsqueeze(1)#.view(B, 1, 3)\n",
        "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
        "        mask = dist < distance\n",
        "        distance[mask] = dist[mask]\n",
        "        farthest = torch.max(distance, -1)[1]\n",
        "    return centroids\n",
        "\n",
        "\n",
        "def query_ball_point(radius, nsample, xyz, new_xyz):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        radius: local region radius\n",
        "        nsample: max sample number in local region\n",
        "        xyz: all points, [B, N, 3]\n",
        "        new_xyz: query points, [B, S, 3]\n",
        "    Return:\n",
        "        group_idx: grouped points index, [B, S, nsample]\n",
        "    \"\"\"\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.shape\n",
        "    _, S, _ = new_xyz.shape\n",
        "    group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1])\n",
        "    sqrdists = square_distance(new_xyz, xyz)\n",
        "    group_idx[sqrdists > radius ** 2] = N\n",
        "    group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]\n",
        "    group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])\n",
        "    mask = group_idx == N\n",
        "    group_idx[mask] = group_first[mask]\n",
        "    return group_idx\n",
        "\n",
        "\n",
        "def sample_and_group(npoint, radius, nsample, xyz, points, returnfps=False):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        npoint:\n",
        "        radius:\n",
        "        nsample:\n",
        "        xyz: input points position data, [B, N, 3]\n",
        "        points: input points data, [B, N, D]\n",
        "    Return:\n",
        "        new_xyz: sampled points position data, [B, npoint, nsample, 3]\n",
        "        new_points: sampled points data, [B, npoint, nsample, 3+D]\n",
        "    \"\"\"\n",
        "    B, N, C = xyz.shape\n",
        "    S = npoint\n",
        "    fps_idx = farthest_point_sample(xyz, npoint) # [B, npoint, C]\n",
        "    new_xyz = index_points(xyz, fps_idx)\n",
        "    idx = query_ball_point(radius, nsample, xyz, new_xyz)\n",
        "    grouped_xyz = index_points(xyz, idx) # [B, npoint, nsample, C]\n",
        "    grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, C)\n",
        "\n",
        "    if points is not None:\n",
        "        grouped_points = index_points(points, idx)\n",
        "        new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1) # [B, npoint, nsample, C+D]\n",
        "    else:\n",
        "        new_points = grouped_xyz_norm\n",
        "    if returnfps:\n",
        "        return new_xyz, new_points, grouped_xyz, fps_idx\n",
        "    else:\n",
        "        return new_xyz, new_points\n",
        "\n",
        "def sample_and_group_all(xyz, points):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        xyz: input points position data, [B, N, 3]\n",
        "        points: input points data, [B, N, D]\n",
        "    Return:\n",
        "        new_xyz: sampled points position data, [B, 1, 3]\n",
        "        new_points: sampled points data, [B, 1, N, 3+D]\n",
        "    \"\"\"\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.shape\n",
        "    new_xyz = torch.zeros(B, 1, C).to(device)\n",
        "    grouped_xyz = xyz.view(B, 1, N, C)\n",
        "    if points is not None:\n",
        "        new_points = torch.cat([grouped_xyz, points.view(B, 1, N, -1)], dim=-1)\n",
        "    else:\n",
        "        new_points = grouped_xyz\n",
        "    return new_xyz, new_points"
      ],
      "metadata": {
        "id": "4ngrRXszdnLa"
      },
      "execution_count": 447,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 448,
      "metadata": {
        "id": "VQFhP2_3cO83"
      },
      "outputs": [],
      "source": [
        "class PointNetSetAbstraction(nn.Module):\n",
        "    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all):\n",
        "        super(PointNetSetAbstraction, self).__init__()\n",
        "        self.npoint = npoint\n",
        "        self.radius = radius\n",
        "        self.nsample = nsample\n",
        "        self.mlp_convs = nn.ModuleList()\n",
        "        self.mlp_bns = nn.ModuleList()\n",
        "        last_channel = in_channel\n",
        "        for out_channel in mlp:\n",
        "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
        "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
        "            last_channel = out_channel\n",
        "        self.group_all = group_all\n",
        "\n",
        "    def forward(self, xyz, points):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            xyz: input points position data, [B, C, N]\n",
        "            points: input points data, [B, D, N]\n",
        "        Return:\n",
        "            new_xyz: sampled points position data, [B, C, S]\n",
        "            new_points_concat: sample points feature data, [B, D', S]\n",
        "        \"\"\"\n",
        "        xyz = xyz.permute(0, 2, 1)\n",
        "        if points is not None:\n",
        "            points = points.permute(0, 2, 1)\n",
        "\n",
        "        if self.group_all:\n",
        "            new_xyz, new_points = sample_and_group_all(xyz, points)\n",
        "        else:\n",
        "            new_xyz, new_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, points)\n",
        "        # new_xyz: sampled points position data, [B, npoint, C]\n",
        "        # new_points: sampled points data, [B, npoint, nsample, C+D]\n",
        "        new_points = new_points.permute(0, 3, 2, 1) # [B, C+D, nsample,npoint]\n",
        "        for i, conv in enumerate(self.mlp_convs):\n",
        "            bn = self.mlp_bns[i]\n",
        "            new_points =  F.relu(bn(conv(new_points)))\n",
        "\n",
        "        new_points = torch.max(new_points, 2)[0]\n",
        "        new_xyz = new_xyz.permute(0, 2, 1)\n",
        "        return new_xyz, new_points"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Net"
      ],
      "metadata": {
        "id": "fuHNCwFn2mL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class get_model(nn.Module):\n",
        "    def __init__(self,num_class,normal_channel=False):\n",
        "        super(get_model, self).__init__()\n",
        "        in_channel = 6 if normal_channel else 3\n",
        "        self.normal_channel = normal_channel\n",
        "        self.sa1 = PointNetSetAbstraction(npoint=512, radius=0.2, nsample=32, in_channel=in_channel, mlp=[64, 64, 128], group_all=False)\n",
        "        self.sa2 = PointNetSetAbstraction(npoint=128, radius=0.4, nsample=64, in_channel=128 + 3, mlp=[128, 128, 256], group_all=False)\n",
        "        self.sa3 = PointNetSetAbstraction(npoint=None, radius=None, nsample=None, in_channel=256 + 3, mlp=[256, 512, 1024], group_all=True)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.drop1 = nn.Dropout(0.4)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.drop2 = nn.Dropout(0.4)\n",
        "        self.fc3 = nn.Linear(256, num_class)\n",
        "\n",
        "    def forward(self, xyz):\n",
        "        B, _, _ = xyz.shape\n",
        "        if self.normal_channel:\n",
        "            norm = xyz[:, 3:, :]\n",
        "            xyz = xyz[:, :3, :]\n",
        "        else:\n",
        "            norm = None\n",
        "        l1_xyz, l1_points = self.sa1(xyz, norm)\n",
        "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
        "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
        "        x = l3_points.view(B, 1024)\n",
        "        x = self.drop1(F.relu(self.bn1(self.fc1(x))))\n",
        "        x = self.drop2(F.relu(self.bn2(self.fc2(x))))\n",
        "        x = self.fc3(x)\n",
        "        x = F.linear(x)\n",
        "\n",
        "\n",
        "        return x, l3_points"
      ],
      "metadata": {
        "id": "Uas0VA3td-P2"
      },
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = get_model(num_class=6)"
      ],
      "metadata": {
        "id": "huv76ogHeinK"
      },
      "execution_count": 450,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tensorflow"
      ],
      "metadata": {
        "id": "O_Avfk_f9mqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.10"
      ],
      "metadata": {
        "id": "iRK5n1ZT86hU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SF1DNc5E-AWQ",
        "outputId": "70efab94-3216-4835-807c-0b7d83bbe547"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.10.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def index_points(points, idx):\n",
        "    \"\"\"\n",
        "\n",
        "    Input:\n",
        "        points: input points data, [B, N, C]\n",
        "        idx: sample index data, [B, S]\n",
        "    Return:\n",
        "        new_points:, indexed points data, [B, S, C]\n",
        "    \"\"\"\n",
        "    B, _, _ = points.shape\n",
        "    view_shape = list(idx.shape)\n",
        "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
        "    repeat_shape = list(idx.shape)\n",
        "    repeat_shape[0] = 1\n",
        "    batch_indices = tf.range(B, dtype=tf.int32)\n",
        "    batch_indices = tf.reshape(batch_indices, shape=view_shape)  # reshape to view_shape\n",
        "    batch_indices = tf.tile(batch_indices, multiples=repeat_shape)  # repeat according to repeat_shape\n",
        "    new_points = tf.gather(points, idx, axis=1, batch_dims=1)\n",
        "    return new_points\n",
        "\n",
        "def farthest_point_sample(npoint, xyz):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        xyz: pointcloud data, [B, N, 3]\n",
        "        npoint: number of samples\n",
        "    Return:\n",
        "        centroids: sampled pointcloud index, [B, npoint]\n",
        "    \"\"\"\n",
        "    B, N, C = xyz.shape\n",
        "    centroids = tf.TensorArray(dtype=tf.int32, size=npoint, dynamic_size=False)\n",
        "    distance = tf.ones((B, N), dtype=tf.float32) * 1e10\n",
        "    farthest = tf.random.uniform((B,), minval=0, maxval=N, dtype=tf.int32)\n",
        "    batch_indices = tf.range(B, dtype=tf.int32)\n",
        "\n",
        "    def loop_body(i, centroids, distance, farthest):\n",
        "        centroids = centroids.write(i, farthest)\n",
        "        centroid = tf.gather(xyz, farthest, batch_dims=1)[:, tf.newaxis, :]  # [B, 1, 3]\n",
        "        dist = tf.reduce_sum((xyz - centroid) ** 2, axis=-1)  # [B, N]\n",
        "        mask = dist < distance\n",
        "        distance = tf.where(mask, dist, distance)\n",
        "        farthest = tf.argmax(distance, axis=-1, output_type=tf.int32)\n",
        "        return i + 1, centroids, distance, farthest\n",
        "\n",
        "    _, centroids, _, _ = tf.while_loop(\n",
        "        lambda i, *args: i < npoint,\n",
        "        loop_body,\n",
        "        [0, centroids, distance, farthest]\n",
        "    )\n",
        "\n",
        "    return tf.transpose(centroids.stack(), perm=[1, 0])  # [B, npoint]\n",
        "\n",
        "def square_distance(src, dst):\n",
        "    \"\"\"\n",
        "    Compute squared distances between two point sets.\n",
        "    Input:\n",
        "        src: source points, [B, N, C]\n",
        "        dst: target points, [B, M, C]\n",
        "    Output:\n",
        "        dist: squared distances, [B, N, M]\n",
        "    \"\"\"\n",
        "    dist = tf.reduce_sum(src**2, axis=-1, keepdims=True) - \\\n",
        "           2 * tf.matmul(src, tf.transpose(dst, perm=[0, 2, 1])) + \\\n",
        "           tf.transpose(tf.reduce_sum(dst**2, axis=-1, keepdims=True), perm=[0, 2, 1])\n",
        "    return tf.maximum(dist, 0)  # Avoid small negative values due to floating-point errors\n",
        "\n",
        "\n",
        "def query_ball_point(radius, nsample, xyz, new_xyz):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        radius: local region radius\n",
        "        nsample: max sample number in local region\n",
        "        xyz: all points, [B, N, 3]\n",
        "        new_xyz: query points, [B, S, 3]\n",
        "    Return:\n",
        "        group_idx: grouped points index, [B, S, nsample]\n",
        "    \"\"\"\n",
        "    B, N, C = xyz.shape\n",
        "    S = tf.shape(new_xyz)[1]\n",
        "\n",
        "    # Generate group indices [1, 1, N] -> [B, S, N]\n",
        "    group_idx = tf.tile(tf.range(N, dtype=tf.int32)[tf.newaxis, tf.newaxis, :], [B, S, 1])\n",
        "\n",
        "    # Compute squared distances between new_xyz and xyz\n",
        "    sqrdists = square_distance(new_xyz, xyz)\n",
        "\n",
        "    # Mask out points outside the radius\n",
        "    group_idx = tf.where(sqrdists > radius**2, N, group_idx)\n",
        "\n",
        "    # Sort and select the top nsample points\n",
        "    group_idx = tf.sort(group_idx, axis=-1)[:, :, :nsample]\n",
        "\n",
        "    # Handle cases where there are fewer than nsample points within the radius\n",
        "    group_first = tf.tile(group_idx[:, :, 0:1], [1, 1, nsample])  # Repeat the first valid index\n",
        "    mask = tf.equal(group_idx, N)\n",
        "    group_idx = tf.where(mask, group_first, group_idx)\n",
        "\n",
        "    return group_idx\n",
        "\n",
        "def sample_and_group(npoint, radius, nsample, xyz, points, use_xyz=True):\n",
        "    '''\n",
        "    Input:\n",
        "        npoint: int32\n",
        "        radius: float32\n",
        "        nsample: int32\n",
        "        xyz: (batch_size, ndataset, 3) TF tensor\n",
        "        points: (batch_size, ndataset, channel) TF tensor, if None will just use xyz as points\n",
        "        knn: bool, if True use kNN instead of radius search\n",
        "        use_xyz: bool, if True concat XYZ with local point features, otherwise just use point features\n",
        "    Output:\n",
        "        new_xyz: (batch_size, npoint, 3) TF tensor\n",
        "        new_points: (batch_size, npoint, nsample, 3+channel) TF tensor\n",
        "        idx: (batch_size, npoint, nsample) TF tensor, indices of local points as in ndataset points\n",
        "        grouped_xyz: (batch_size, npoint, nsample, 3) TF tensor, normalized point XYZs\n",
        "            (subtracted by seed point XYZ) in local regions\n",
        "    '''\n",
        "\n",
        "    # Farthest point sampling\n",
        "    fps_idx = farthest_point_sample(npoint, xyz)\n",
        "    new_xyz = index_points(xyz, fps_idx) # (batch_size, npoint, 3)\n",
        "\n",
        "    # Ball query\n",
        "    idx = query_ball_point(radius, nsample, xyz, new_xyz)\n",
        "    grouped_xyz = index_points(xyz, idx) # (batch_size, npoint, nsample, 3)\n",
        "    grouped_xyz -= tf.tile(tf.expand_dims(new_xyz, 2), [1,1,nsample,1]) # translation normalization\n",
        "\n",
        "    # Concatenate point features if provided\n",
        "    if points is not None:\n",
        "        grouped_points = index_points(points, idx) # (batch_size, npoint, nsample, channel)\n",
        "        if use_xyz:\n",
        "            new_points = tf.concat([grouped_xyz, grouped_points], axis=-1) # (batch_size, npoint, nample, 3+channel)\n",
        "        else:\n",
        "            new_points = grouped_points\n",
        "    else:\n",
        "      new_points = grouped_xyz\n",
        "\n",
        "    return new_xyz, new_points, idx, grouped_xyz\n",
        "\n",
        "def sample_and_group_all(xyz, points, use_xyz=True):\n",
        "    '''\n",
        "    Inputs:\n",
        "        xyz: (batch_size, ndataset, 3) TF tensor\n",
        "        points: (batch_size, ndataset, channel) TF tensor, if None will just use xyz as points\n",
        "        use_xyz: bool, if True concat XYZ with local point features, otherwise just use point features\n",
        "    Outputs:\n",
        "        new_xyz: (batch_size, 1, 3) as (0,0,0)\n",
        "        new_points: (batch_size, 1, ndataset, 3+channel) TF tensor\n",
        "    Note:\n",
        "        Equivalent to sample_and_group with npoint=1, radius=inf, use (0,0,0) as the centroid\n",
        "    '''\n",
        "    batch_size, nsample, _ = xyz.shape\n",
        "    new_xyz = tf.constant(np.tile(np.array([0,0,0]).reshape((1,1,3)), (batch_size,1,1)),dtype=tf.float32) # (batch_size, 1, 3)\n",
        "    idx = tf.constant(np.tile(np.array(range(nsample)).reshape((1,1,nsample)), (batch_size,1,1)))\n",
        "    grouped_xyz = tf.reshape(xyz, (batch_size, 1, nsample, 3)) # (batch_size, npoint=1, nsample, 3)\n",
        "    if points is not None:\n",
        "        if use_xyz:\n",
        "            new_points = tf.concat([xyz, points], axis=2) # (batch_size, 16, 259)\n",
        "        else:\n",
        "            new_points = points\n",
        "        new_points = tf.expand_dims(new_points, 1) # (batch_size, 1, 16, 259)\n",
        "    else:\n",
        "        new_points = grouped_xyz\n",
        "    return new_xyz, new_points, idx, grouped_xyz"
      ],
      "metadata": {
        "id": "8boiWDE79mdV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pointnet_sa_module(xyz, points, npoint, radius, nsample, mlp, group_all, pooling='max', use_xyz=True, use_nchw=False):\n",
        "    ''' PointNet Set Abstraction (SA) Module\n",
        "        Input:\n",
        "            xyz: (batch_size, ndataset, 3) TF tensor\n",
        "            points: (batch_size, ndataset, channel) TF tensor\n",
        "            npoint: int32 -- #points sampled in farthest point sampling\n",
        "            radius: float32 -- search radius in local region\n",
        "            nsample: int32 -- how many points in each local region\n",
        "            mlp: list of int32 -- output size for MLP on each point\n",
        "            mlp2: list of int32 -- output size for MLP on each region\n",
        "            group_all: bool -- group all points into one PC if set true, OVERRIDE\n",
        "                npoint, radius and nsample settings\n",
        "            use_xyz: bool, if True concat XYZ with local point features, otherwise just use point features\n",
        "            use_nchw: bool, if True, use NCHW data format for conv2d, which is usually faster than NHWC format\n",
        "        Return:\n",
        "            new_xyz: (batch_size, npoint, 3) TF tensor\n",
        "            new_points: (batch_size, npoint, mlp[-1] or mlp2[-1]) TF tensor\n",
        "            idx: (batch_size, npoint, nsample) int32 -- indices for local regions\n",
        "    '''\n",
        "\n",
        "    # Sample and Grouping\n",
        "    if group_all:\n",
        "        _, nsample, _ = tf.shape(xyz)\n",
        "        new_xyz, new_points, idx, grouped_xyz = sample_and_group_all(xyz, points, use_xyz)\n",
        "    else:\n",
        "        new_xyz, new_points, idx, grouped_xyz = sample_and_group(npoint, radius, nsample, xyz, points, use_xyz)\n",
        "\n",
        "    # Point Feature Embedding\n",
        "    if use_nchw: new_points = tf.transpose(new_points, [0,3,1,2])\n",
        "    for i, num_out_channel in enumerate(mlp):\n",
        "       new_points = tf.keras.layers.Conv2D(num_out_channel, [1,1], padding='valid', activation='relu')(new_points)\n",
        "\n",
        "    if use_nchw: new_points = tf.transpose(new_points, [0,2,3,1])\n",
        "\n",
        "    # Pooling in Local Regions\n",
        "    if pooling=='max':\n",
        "        new_points = tf.reduce_max(new_points, axis=[2], keepdims=True, name='maxpool')\n",
        "    '''\n",
        "    elif pooling=='avg':\n",
        "        new_points = tf.reduce_mean(new_points, axis=[2], keepdims=True, name='avgpool')\n",
        "    elif pooling=='weighted_avg':\n",
        "        #with tf.variable_scope('weighted_avg'):\n",
        "        dists = tf.norm(grouped_xyz,axis=-1,ord=2,keepdims=True)\n",
        "        exp_dists = tf.exp(-dists * 5)\n",
        "        weights = exp_dists/tf.reduce_sum(exp_dists,axis=2,keepdims=True) # (batch_size, npoint, nsample, 1)\n",
        "        new_points *= weights # (batch_size, npoint, nsample, mlp[-1])\n",
        "        new_points = tf.reduce_sum(new_points, axis=2, keepdims=True)\n",
        "    elif pooling=='max_and_avg':\n",
        "        max_points = tf.reduce_max(new_points, axis=[2], keepdims=True, name='maxpool')\n",
        "        avg_points = tf.reduce_mean(new_points, axis=[2], keepdims=True, name='avgpool')\n",
        "        new_points = tf.concat([avg_points, max_points], axis=-1)\n",
        "    '''\n",
        "    new_points = tf.squeeze(new_points, [2]) # (batch_size, npoints, mlp2[-1])\n",
        "    return new_xyz, new_points, idx"
      ],
      "metadata": {
        "id": "bG2fbeJX0awL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SampleAndGroup(tf.keras.layers.Layer):\n",
        "    def __init__(self, npoint, radius, nsample, use_xyz=True, **kwargs):\n",
        "      super(SampleAndGroup, self).__init__(**kwargs)\n",
        "      self.npoint = npoint\n",
        "      self.radius = radius\n",
        "      self.nsample = nsample\n",
        "      self.use_xyz = use_xyz\n",
        "\n",
        "    def call(self, xyz, points):\n",
        "      return sample_and_group(self.npoint, self.radius, self.nsample, xyz, points, self.use_xyz)\n",
        "\n",
        "class SampleAndGroupAll(tf.keras.layers.Layer):\n",
        "    def __init__(self, use_xyz=True, **kwargs):\n",
        "      super(SampleAndGroupAll, self).__init__(**kwargs)\n",
        "      self.use_xyz = use_xyz\n",
        "\n",
        "    def call(self, xyz, points):\n",
        "      return sample_and_group_all(xyz, points, self.use_xyz)"
      ],
      "metadata": {
        "id": "a1ZEZNgV9u3j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNetSAModule(tf.keras.layers.Layer):\n",
        "    def __init__(self, npoint, radius, nsample, mlp, group_all, pooling='max', use_xyz=True, use_nchw=False, **kwargs):\n",
        "        super(PointNetSAModule, self).__init__(**kwargs)\n",
        "        self.npoint = npoint\n",
        "        self.radius = radius\n",
        "        self.nsample = nsample\n",
        "        self.mlp = mlp\n",
        "        self.group_all = group_all\n",
        "        self.pooling = pooling\n",
        "        self.use_xyz = use_xyz\n",
        "        self.use_nchw = use_nchw\n",
        "\n",
        "        # Create Conv2D layers for the MLP in advance\n",
        "        self.conv_layers = [\n",
        "            tf.keras.layers.Conv2D(num_out_channel, [1, 1], padding='valid', activation='relu')\n",
        "            for num_out_channel in self.mlp\n",
        "        ]\n",
        "\n",
        "    def call(self, xyz, points):\n",
        "        # Sample and Grouping\n",
        "        _, nsample, _ = xyz.shape\n",
        "        if self.group_all:\n",
        "            new_xyz, new_points, idx, grouped_xyz = SampleAndGroupAll(self.use_xyz)(xyz, points)\n",
        "        else:\n",
        "            new_xyz, new_points, idx, grouped_xyz = SampleAndGroup(self.npoint, self.radius, nsample, self.use_xyz)(xyz, points)\n",
        "\n",
        "        # Point Feature Embedding\n",
        "        if self.use_nchw:\n",
        "            new_points = tf.transpose(new_points, [0, 3, 1, 2])\n",
        "\n",
        "        for conv in self.conv_layers:  # Apply the pre-created Conv2D layers\n",
        "            new_points = conv(new_points)\n",
        "\n",
        "        if self.use_nchw:\n",
        "            new_points = tf.transpose(new_points, [0, 2, 3, 1])\n",
        "\n",
        "        # Pooling in Local Regions\n",
        "        if self.pooling == 'max':\n",
        "            new_points = tf.reduce_max(new_points, axis=[2], keepdims=True, name='maxpool')\n",
        "\n",
        "        new_points = tf.squeeze(new_points, [2])  # (batch_size, npoints, mlp[-1])\n",
        "        return new_xyz, new_points, idx\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PointNetSAModule, self).get_config()\n",
        "        config.update({\n",
        "            'npoint': self.npoint,  # Assuming these are attributes of your PointNetSAModule\n",
        "            'radius': self.radius,\n",
        "            'nsample': self.nsample,\n",
        "            'mlp': self.mlp,\n",
        "            'group_all': self.group_all,\n",
        "            'pooling': self.pooling,\n",
        "            'use_xyz': self.use_xyz,\n",
        "            'use_nchw': self.use_nchw,\n",
        "        })\n",
        "        return config"
      ],
      "metadata": {
        "id": "WHtA0zX4TJS4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PointNet2(n_outs, batch_size):\n",
        "    \"\"\" Classification PointNet, input is BxNx3, output BxN_classes \"\"\"\n",
        "    inputs = tf.keras.Input(shape=(1024, 3), batch_size=batch_size)\n",
        "\n",
        "    l0_xyz = inputs\n",
        "    l0_points = None\n",
        "\n",
        "    # Set abstraction layers\n",
        "    l1_xyz, l1_points, l1_indices = PointNetSAModule(npoint=512, radius=0.2, nsample=32, mlp=[64,64,128], group_all=False, use_nchw=True)(l0_xyz, l0_points)\n",
        "    l2_xyz, l2_points, l2_indices = PointNetSAModule(npoint=128, radius=0.4, nsample=64, mlp=[128,128,256], group_all=False)(l1_xyz, l1_points)\n",
        "    l3_xyz, l3_points, l3_indices = PointNetSAModule(npoint=None, radius=None, nsample=None, mlp=[256,512,1024], group_all=True)(l2_xyz, l2_points)\n",
        "\n",
        "    # Fully connected layers\n",
        "    net = tf.reshape(l3_points, [batch_size, -1])\n",
        "\n",
        "    dense1 = tf.keras.layers.Dense(512)(net)\n",
        "    dense1 = tf.keras.layers.BatchNormalization(momentum=0.0)(dense1)\n",
        "    dense1 = tf.keras.layers.Activation(\"relu\")(dense1)\n",
        "\n",
        "    drop = tf.keras.layers.Dropout(0.3)(dense1)\n",
        "\n",
        "    dense2 = tf.keras.layers.Dense(256)(drop)\n",
        "    dense2 = tf.keras.layers.BatchNormalization(momentum=0.0)(dense2)\n",
        "    dense2 = tf.keras.layers.Activation(\"relu\")(dense2)\n",
        "\n",
        "    drop = tf.keras.layers.Dropout(0.3)(dense2)\n",
        "\n",
        "    outputs = tf.keras.layers.Dense(n_outs, activation=None)(drop)\n",
        "\n",
        "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"PointNet2\")"
      ],
      "metadata": {
        "id": "UbAx4hPM6Kb9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sqrd_euclidean_distance_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Squared Euclidean distance loss\n",
        "    https://en.wikipedia.org/wiki/Euclidean_distance\n",
        "    :param y_true: TensorFlow/Theano tensor\n",
        "    :param y_pred: TensorFlow/Theano tensor of the same shape as y_true\n",
        "    :return: float\n",
        "    \"\"\"\n",
        "    return K.sum(K.square(y_pred - y_true), axis=-1)\n",
        "\n",
        "model = PointNet2(6, 64)\n",
        "\n",
        "# Compiling\n",
        "model.compile(\n",
        "  loss=sqrd_euclidean_distance_loss,\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "  metrics=[sqrd_euclidean_distance_loss],\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbxAagWV8j_h",
        "outputId": "0a229dd5-17ae-4049-e7d6-b5057449c6eb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"PointNet2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(8, 1024, 3)]       0           []                               \n",
            "                                                                                                  \n",
            " point_net_sa_module_3 (PointNe  ((8, 512, 3),       78080       ['input_2[0][0]']                \n",
            " tSAModule)                      (8, 512, 3),                                                     \n",
            "                                 (8, 512, 1024))                                                  \n",
            "                                                                                                  \n",
            " point_net_sa_module_4 (PointNe  ((8, 128, 3),       50432       ['point_net_sa_module_3[0][0]',  \n",
            " tSAModule)                      (8, 128, 256),                   'point_net_sa_module_3[0][1]']  \n",
            "                                 (8, 128, 512))                                                   \n",
            "                                                                                                  \n",
            " point_net_sa_module_5 (PointNe  ((8, 1, 3),         723456      ['point_net_sa_module_4[0][0]',  \n",
            " tSAModule)                      (8, 1, 1024),                    'point_net_sa_module_4[0][1]']  \n",
            "                                 (8, 1, 128))                                                     \n",
            "                                                                                                  \n",
            " tf.reshape_1 (TFOpLambda)      (8, 1024)            0           ['point_net_sa_module_5[0][1]']  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (8, 512)             524800      ['tf.reshape_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (8, 512)            2048        ['dense_3[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (8, 512)             0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (8, 512)             0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (8, 256)             131328      ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (8, 256)            1024        ['dense_4[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (8, 256)             0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (8, 256)             0           ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (8, 6)               1542        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,512,710\n",
            "Trainable params: 1,511,174\n",
            "Non-trainable params: 1,536\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training example\n",
        "\n",
        "'points.npy' is a np.array with size (B, 1024, 3)\n",
        "  containing the point clouds\n",
        "\n",
        "'targets.npy' is a np.array with size (B, 1, 6)\n",
        "  containing the target rotations"
      ],
      "metadata": {
        "id": "AbtfltLCfJNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Loading example files ###\n",
        "array_file = open('points.npy', 'rb')\n",
        "points = np.load(array_file, allow_pickle=True)\n",
        "points = points.astype(np.float32)\n",
        "\n",
        "array_file = open('targets.npy', 'rb')\n",
        "targets = np.load(array_file, allow_pickle=True)\n",
        "targets = targets.astype(np.float32)\n",
        "targets = [np.concatenate((np.array(T[:3,:3][:,0]), np.array(T[:3,:3][:,1]))) for T in targets]"
      ],
      "metadata": {
        "id": "DzGVxgxbg65G"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# BATCH SIZE\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "### Splitting data ###\n",
        "train_points, valid_points, train_targets, valid_targets = train_test_split(points, targets, train_size=0.9, shuffle=True)\n",
        "\n",
        "def augment(points, label):\n",
        "    # jitter points\n",
        "    points += tf.random.uniform(points.shape, -0.00005, 0.00005, dtype=tf.float32)\n",
        "    # shuffle points\n",
        "    points = tf.random.shuffle(points)\n",
        "    return points, label\n",
        "\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_points, train_targets))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((valid_points, valid_targets))\n",
        "\n",
        "train_dataset = train_dataset.shuffle(len(train_points)).map(augment).batch(batch_size, drop_remainder=True)\n",
        "valid_dataset = valid_dataset.shuffle(len(valid_points)).map(augment).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "print('Dataset splitted!')\n",
        "print(f'train: {len(train_dataset)}\\nvalidation: {len(valid_dataset)}')\n",
        "\n",
        "points = 0\n",
        "targets = 0\n",
        "train_points = 0\n",
        "valid_points = 0\n",
        "train_targets = 0\n",
        "valid_targets = 0\n",
        "\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(f'best_model.hdf5', monitor='val_loss', verbose=1,\n",
        "    save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iySVIi7xfLT2",
        "outputId": "158d99de-7b34-490e-c783-7386adfdb3ca"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset splitted!\n",
            "train: 11\n",
            "validation: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=1500, validation_data=valid_dataset, callbacks=[checkpoint], verbose=0)"
      ],
      "metadata": {
        "id": "glRUJaMPfq6_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
